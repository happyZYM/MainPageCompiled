<!DOCTYPE html>
<html lang="cn">
  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <!-- Metadata, OpenGraph and Schema.org -->

  <!-- Website verification -->
  
    <meta name="google-site-verification" content="1Cnu0ucc1Z1BLtJOrgka47EbLoJHU5DQysgRqEItJHk">
  
  
    <meta name="msvalidate.01" content="C7E8083B2CB996923E3E7F6BFC0B60CF">
  
  <!--
    Avoid warning on Google Chrome Error with Permissions-Policy header:
    Origin trial controlled feature not enabled: 'interest-cohort'.
    see https://stackoverflow.com/a/75119417
  -->
  <meta http-equiv="Permissions-Policy" content="interest-cohort=()">




<!-- Standard metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title>
  
  
    
      在accelerate框架中精确恢复dataloader状态的方法 | Yumin Zhuang
    
  
</title>
<meta name="author" content="Yumin Zhuang">
<meta name="description" content="ZYM's main page.
">

  <meta name="keywords" content="academic-website, Astricaelus, ZhuangYumin">










<!-- Bootstrap & MDB -->
<link rel="stylesheet" href="/assets/css/bootstrap.min.css?b05f9a0b7405d7c8c89c7465593dea81">
<link rel="stylesheet" href="/assets/libs/mdb/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">



<!-- Fonts & Icons -->
<link defer rel="stylesheet" href="/assets/css/academicons.min.css?dadeb9c5d1fd12bc8d37475657446863">
<link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772">
<link defer rel="stylesheet" type="text/css" href="/assets/libs/google_fonts/google-fonts.css">

<!-- Code Syntax Highlighting -->
<link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light">



<!-- Styles -->




  <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%98%8E&lt;/text&gt;&lt;/svg&gt;">

<link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e">
<link rel="canonical" href="https://zhuangyumin.dev/blog/2025/accelerate-dataloader-accurate-resuming/">


  <!-- Dark Mode -->
  <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script>
  <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark">
  <script>
    initTheme();
  </script>










  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">
    <!-- Header -->
    <header>
  <!-- Nav Bar -->
  <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation">
    <div class="container">
      
        <a class="navbar-brand title font-weight-lighter" href="/">
          
            
              <span class="font-weight-bold">Yumin</span>
            
            
            Zhuang
          
        </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>

      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          

          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">About
              
            </a>
          </li>

          <!-- Other pages -->
          
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
              
                
                <li class="nav-item active">
                  <a class="nav-link" href="/blog/">Blog
                    
                  </a>
                </li>
              
            
          
            
              
                
                <li class="nav-item ">
                  <a class="nav-link" href="/publications/">Publications
                    
                  </a>
                </li>
              
            
          
            
              
                
                <li class="nav-item ">
                  <a class="nav-link" href="/teaching/">Teaching
                    
                  </a>
                </li>
              
            
          
            
          
            
              
                
                <li class="nav-item ">
                  <a class="nav-link" href="/news/">News
                    
                  </a>
                </li>
              
            
          
          
            <!-- Search -->
            <li class="nav-item">
              <button id="search-toggle" title="Search" onclick="openSearchModal()">
                <span class="nav-link">ctrl k <i class="ti ti-search"></i></span>
              </button>
            </li>
          
          
            <!-- Toogle theme mode -->
            <li class="toggle-container">
              <button id="light-toggle" title="Change theme">
                <i class="ti ti-sun-moon" id="light-toggle-system"></i>
                <i class="ti ti-moon-filled" id="light-toggle-dark"></i>
                <i class="ti ti-sun-filled" id="light-toggle-light"></i>
              </button>
            </li>
          
        </ul>
      </div>
    </div>
  </nav>
  
    <!-- Scrolling Progress Bar -->
    <progress id="progress" value="0">
      <div class="progress-container">
        <span class="progress-bar"></span>
      </div>
    </progress>
  
</header>


    <!-- Content -->
    <div class="container mt-5" role="main">
      
        






<div class="post">
  <header class="post-header">
    <h1 class="post-title">在accelerate框架中精确恢复dataloader状态的方法</h1>
    <p class="post-meta">
      Created on December 03, 2025
      
      
      
    </p>
    <p class="post-tags">
      
        <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>
      
      
          ·  
        
          
            <a href="/blog/tag/engineer"> <i class="fa-solid fa-hashtag fa-sm"></i> Engineer</a>
          
          
        
      

      
          ·  
        
          
            <a href="/blog/category/computerscience"> <i class="fa-solid fa-tag fa-sm"></i> ComputerScience</a>
          
          
        
      
    </p>
  </header>

  <article class="post-content">
    
      <div id="table-of-contents">
        <ul id="toc" class="section-nav">
<li class="toc-entry toc-h1"><a href="#%E5%90%84%E7%B1%BB%E6%96%B9%E6%A1%88%E7%9A%84%E6%AF%94%E5%AF%B9%E5%88%86%E6%9E%90">各类方案的比对分析</a></li>
<li class="toc-entry toc-h1">
<a href="#%E6%B5%8B%E8%AF%95">测试</a>
<ul>
<li class="toc-entry toc-h2"><a href="#test-1">Test 1</a></li>
<li class="toc-entry toc-h2"><a href="#test-2">Test 2</a></li>
<li class="toc-entry toc-h2"><a href="#test-3">Test 3</a></li>
<li class="toc-entry toc-h2"><a href="#test-4">Test 4</a></li>
<li class="toc-entry toc-h2"><a href="#test-5">Test 5</a></li>
</ul>
</li>
</ul>
      </div>
      <hr>
    
    <div id="markdown-content">
      <h1 id="各类方案的比对分析">各类方案的比对分析</h1>

<p>不难发现，在使用accelerate框架时，<code class="language-plaintext highlighter-rouge">accelerator.load_state</code>只能可靠地恢复model、optimizer、scheduler的状态，而dataloader的状态恢复，里面有许多坑。</p>

<p>从原理上来讲，在accelerate框架里，对于一个启用了shuffle的dataloaer，如果要想精确恢复：</p>

<ul>
  <li>要么完全和model、optimizer、scheduler相同，可以保存/加载内部状态 (stateful dataloader)</li>
  <li>要么dataloader初始化时从全局随机环境提取一个种子存入内部状态，此后正常进行iteration时不再与全局随机环境发生关联，只依赖内部状态 (seedable sampler)</li>
</ul>

<p>简单来讲，要么状态可以瞬间重置到正确的位置，要么在快进时不对外输入输出任何影响。</p>

<p>一个典型的反面例子是普通dataloaer+手动skip（纯手写或用skip_first_batches来skip）。普通dataloader在iteration的时候是依赖全局随机环境的，而skip开始前的全局随机环境没有被恢复，skip过程中的全局随机环境变化也与上次运行时的实际情况不符，除非再额外引入一些更加繁琐的机制加以复原，否则这种方法不可能精确恢复dataloader的状态。</p>

<p>accelerate官方文档里主要提到了两类解法：</p>

<ul>
  <li>Stateful Dataloader: accelerate虽然声称支持新版torchdata里的StatefulDataloader，但是issue里有大量反馈存在各种兼容性bug。（我自己也碰到过这种兼容性bug，虽然甚至连怎么不兼容都无法准确复现）</li>
  <li>skip_first_batches: <code class="language-plaintext highlighter-rouge">accelerator.skip_first_batches</code>方案看起来稍微好一点，但是实质上和纯手动skip相同，因此同样无法解决随机环境无法复现的问题。</li>
</ul>

<p>在使用deepwiki查看源码，以及浏览了issue <a href="https://github.com/huggingface/accelerate/issues/3242" rel="external nofollow noopener" target="_blank">https://github.com/huggingface/accelerate/issues/3242</a> 之后，我发现<code class="language-plaintext highlighter-rouge">use_seedable_sampler</code>是一个比较好的方案。虽然 <a href="https://github.com/huggingface/accelerate/issues/3398" rel="external nofollow noopener" target="_blank">https://github.com/huggingface/accelerate/issues/3398</a> 声称这个也有bug，不过我在<code class="language-plaintext highlighter-rouge">v1.11.0</code>里面没有复现，可能已被某个PR修复。（并且这个方案的原理相当简单可靠，没有过于明显的bug之后应该不至于撞上什么特例）</p>

<p>以下是基于<code class="language-plaintext highlighter-rouge">accelerate==1.11.0</code>做的验证实验</p>

<h1 id="测试">测试</h1>

<h2 id="test-1">Test 1</h2>

<p>对于程序：</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">from</span> <span class="n">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">Dataset</span>

<span class="kn">from</span> <span class="n">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>
<span class="kn">from</span> <span class="n">accelerate.utils</span> <span class="kn">import</span> <span class="n">set_seed</span><span class="p">,</span> <span class="n">DataLoaderConfiguration</span>
<span class="kn">import</span> <span class="n">os</span>

<span class="c1"># from torchdata.stateful_dataloader import StatefulDataLoader
</span>
<span class="c1"># Simple dataset with 10 elements
</span><span class="k">class</span> <span class="nc">SimpleDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

<span class="c1"># Function to print batch order in an epoch
</span><span class="k">def</span> <span class="nf">print_epoch_batches</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">interrupt</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>

    <span class="n">output</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="se">\n</span><span class="s">--- Process </span><span class="si">{</span><span class="n">accelerator</span><span class="p">.</span><span class="n">process_index</span><span class="si">}</span><span class="s"> ---</span><span class="se">\n</span><span class="sh">"</span>
    <span class="n">output</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">Epoch </span><span class="si">{</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s">:</span><span class="se">\n</span><span class="sh">"</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
        <span class="n">data</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">batch</span><span class="p">.</span><span class="nf">tolist</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">interrupt</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">accelerator</span><span class="p">.</span><span class="nf">save_state</span><span class="p">(</span><span class="n">output_dir</span><span class="o">=</span><span class="sh">"</span><span class="s">debug_data_order_checkpoints</span><span class="sh">"</span><span class="p">)</span>
            <span class="n">output</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">Random state saved</span><span class="se">\n</span><span class="sh">"</span>
    <span class="n">output</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">data</span><span class="si">}</span><span class="se">\n</span><span class="sh">"</span>
    <span class="k">return</span> <span class="n">output</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="sh">"</span><span class="s">__main__</span><span class="sh">"</span><span class="p">:</span>
    <span class="n">accelerator</span> <span class="o">=</span> <span class="nc">Accelerator</span><span class="p">()</span>
    <span class="nf">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

    <span class="c1"># Create the dataset and DataLoader with shuffle=True
</span>    <span class="n">dataset</span> <span class="o">=</span> <span class="nc">SimpleDataset</span><span class="p">()</span>
    <span class="n">dataloader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span>
        <span class="n">dataset</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">dataloader</span> <span class="o">=</span> <span class="n">accelerator</span><span class="p">.</span><span class="nf">prepare</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>

    <span class="c1"># Check data order for 3 epochs
</span>    <span class="n">all_outputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
        <span class="n">epoch_output</span> <span class="o">=</span> <span class="nf">print_epoch_batches</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">interrupt</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">all_outputs</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">epoch_output</span><span class="p">)</span>

    <span class="c1"># Print all outputs at the end
</span>    <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">all_outputs</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

    <span class="n">accelerator</span><span class="p">.</span><span class="nf">wait_for_everyone</span><span class="p">()</span>

    <span class="c1"># Resume from checkpoint
</span>    <span class="n">accelerator</span> <span class="o">=</span> <span class="nc">Accelerator</span><span class="p">(</span>
        <span class="c1"># dataloader_config=dataloader_config,
</span>    <span class="p">)</span>
    <span class="nf">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">dataloader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span>
        <span class="n">dataset</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">dataloader</span> <span class="o">=</span> <span class="n">accelerator</span><span class="p">.</span><span class="nf">prepare</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>

    <span class="c1"># Load random state
</span>    <span class="k">if</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">exists</span><span class="p">(</span><span class="sh">"</span><span class="s">debug_data_order_checkpoints</span><span class="sh">"</span><span class="p">):</span>
        <span class="n">accelerator</span><span class="p">.</span><span class="nf">load_state</span><span class="p">(</span><span class="sh">"</span><span class="s">debug_data_order_checkpoints</span><span class="sh">"</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Random state loaded from debug_data_order_checkpoints</span><span class="sh">"</span><span class="p">)</span>

    <span class="c1"># skip_dataloader = accelerator.skip_first_batches(dataloader, 2)
</span>
    <span class="c1"># Check data order for 1 epoch
</span>    <span class="n">all_outputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">epoch_output</span> <span class="o">=</span> <span class="nf">print_epoch_batches</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">)</span>
        <span class="n">all_outputs</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">epoch_output</span><span class="p">)</span>

    <span class="c1"># Print all outputs at the end
</span>    <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">all_outputs</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</code></pre></div></div>

<p>运行<code class="language-plaintext highlighter-rouge">accelerate launch --multi_gpu --num_processes 2 a.py</code>，输出：</p>

<pre><code class="language-txt">--- Process 0 ---
Epoch 1:
[[4], [8], [1], [0], [5]]


--- Process 0 ---
Epoch 2:
Random state saved
[[6], [3], [5], [7], [1]]


--- Process 0 ---
Epoch 3:
[[3], [9], [1], [7], [2]]


--- Process 1 ---
Epoch 1:
[[2], [9], [7], [3], [6]]


--- Process 1 ---
Epoch 2:
Random state saved
[[2], [8], [4], [9], [0]]


--- Process 1 ---
Epoch 3:
[[4], [0], [8], [6], [5]]

Random state loaded from debug_data_order_checkpointsRandom state loaded from debug_data_order_checkpoints


--- Process 1 ---
Epoch 1:
[[2], [9], [7], [3], [6]]


--- Process 0 ---
Epoch 1:
[[4], [8], [1], [0], [5]]
</code></pre>

<p>可以看出load state不会影响普通dataloader的状态</p>

<h2 id="test-2">Test 2</h2>

<p>对于程序：</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">from</span> <span class="n">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">Dataset</span>

<span class="kn">from</span> <span class="n">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>
<span class="kn">from</span> <span class="n">accelerate.utils</span> <span class="kn">import</span> <span class="n">set_seed</span><span class="p">,</span> <span class="n">DataLoaderConfiguration</span>
<span class="kn">import</span> <span class="n">os</span>

<span class="c1"># from torchdata.stateful_dataloader import StatefulDataLoader
</span>
<span class="c1"># Simple dataset with 10 elements
</span><span class="k">class</span> <span class="nc">SimpleDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

<span class="c1"># Function to print batch order in an epoch
</span><span class="k">def</span> <span class="nf">print_epoch_batches</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">interrupt</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>

    <span class="n">output</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="se">\n</span><span class="s">--- Process </span><span class="si">{</span><span class="n">accelerator</span><span class="p">.</span><span class="n">process_index</span><span class="si">}</span><span class="s"> ---</span><span class="se">\n</span><span class="sh">"</span>
    <span class="n">output</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">Epoch </span><span class="si">{</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s">:</span><span class="se">\n</span><span class="sh">"</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
        <span class="n">data</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">batch</span><span class="p">.</span><span class="nf">tolist</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">interrupt</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">accelerator</span><span class="p">.</span><span class="nf">save_state</span><span class="p">(</span><span class="n">output_dir</span><span class="o">=</span><span class="sh">"</span><span class="s">debug_data_order_checkpoints</span><span class="sh">"</span><span class="p">)</span>
            <span class="n">output</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">Random state saved</span><span class="se">\n</span><span class="sh">"</span>
    <span class="n">output</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">data</span><span class="si">}</span><span class="se">\n</span><span class="sh">"</span>
    <span class="k">return</span> <span class="n">output</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="sh">"</span><span class="s">__main__</span><span class="sh">"</span><span class="p">:</span>
    <span class="n">accelerator</span> <span class="o">=</span> <span class="nc">Accelerator</span><span class="p">()</span>
    <span class="nf">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

    <span class="c1"># Create the dataset and DataLoader with shuffle=True
</span>    <span class="n">dataset</span> <span class="o">=</span> <span class="nc">SimpleDataset</span><span class="p">()</span>
    <span class="n">dataloader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span>
        <span class="n">dataset</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">dataloader</span> <span class="o">=</span> <span class="n">accelerator</span><span class="p">.</span><span class="nf">prepare</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>

    <span class="c1"># Check data order for 3 epochs
</span>    <span class="n">all_outputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
        <span class="n">epoch_output</span> <span class="o">=</span> <span class="nf">print_epoch_batches</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">interrupt</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">all_outputs</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">epoch_output</span><span class="p">)</span>

    <span class="c1"># Print all outputs at the end
</span>    <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">all_outputs</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

    <span class="n">accelerator</span><span class="p">.</span><span class="nf">wait_for_everyone</span><span class="p">()</span>

    <span class="c1"># Resume from checkpoint
</span>    <span class="n">accelerator</span> <span class="o">=</span> <span class="nc">Accelerator</span><span class="p">(</span>
        <span class="c1"># dataloader_config=dataloader_config,
</span>    <span class="p">)</span>
    <span class="nf">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">dataloader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span>
        <span class="n">dataset</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">dataloader</span> <span class="o">=</span> <span class="n">accelerator</span><span class="p">.</span><span class="nf">prepare</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>

    <span class="c1"># Load random state
</span>    <span class="k">if</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">exists</span><span class="p">(</span><span class="sh">"</span><span class="s">debug_data_order_checkpoints</span><span class="sh">"</span><span class="p">):</span>
        <span class="n">accelerator</span><span class="p">.</span><span class="nf">load_state</span><span class="p">(</span><span class="sh">"</span><span class="s">debug_data_order_checkpoints</span><span class="sh">"</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Random state loaded from debug_data_order_checkpoints</span><span class="sh">"</span><span class="p">)</span>

    <span class="c1"># skip_dataloader = accelerator.skip_first_batches(dataloader, 2)
</span>
    <span class="c1"># Check data order for 1 epoch
</span>    <span class="n">all_outputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">):</span>
        <span class="n">current_dataloader</span> <span class="o">=</span> <span class="n">dataloader</span>
        <span class="k">if</span> <span class="n">epoch</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># skip first 2 batches in epoch 2
</span>            <span class="n">current_dataloader</span> <span class="o">=</span> <span class="n">accelerator</span><span class="p">.</span><span class="nf">skip_first_batches</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">epoch_output</span> <span class="o">=</span> <span class="nf">print_epoch_batches</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">current_dataloader</span><span class="p">)</span>
        <span class="n">all_outputs</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">epoch_output</span><span class="p">)</span>

    <span class="c1"># Print all outputs at the end
</span>    <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">all_outputs</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</code></pre></div></div>

<p>运行<code class="language-plaintext highlighter-rouge">accelerate launch --multi_gpu --num_processes 2 a.py</code>，输出</p>

<pre><code class="language-txt">--- Process 0 ---
Epoch 1:
[[4], [8], [1], [0], [5]]


--- Process 0 ---
Epoch 2:
Random state saved
[[6], [3], [5], [7], [1]]


--- Process 0 ---
Epoch 3:
[[3], [9], [1], [7], [2]]


--- Process 1 ---
Epoch 1:
[[2], [9], [7], [3], [6]]


--- Process 1 ---
Epoch 2:
Random state saved
[[2], [8], [4], [9], [0]]


--- Process 1 ---
Epoch 3:
[[4], [0], [8], [6], [5]]

Random state loaded from debug_data_order_checkpoints
Random state loaded from debug_data_order_checkpoints

--- Process 1 ---
Epoch 2:
[[7], [3], [6]]


--- Process 1 ---
Epoch 3:
[[2], [8], [4], [9], [0]]


--- Process 0 ---
Epoch 2:
[[1], [0], [5]]


--- Process 0 ---
Epoch 3:
[[6], [3], [5], [7], [1]]
</code></pre>

<p>可以看出普通DataLoader+skip_first_batches不可能正确恢复epoch不是第一个的情况</p>

<h2 id="test-3">Test 3</h2>

<p>对于程序：</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">from</span> <span class="n">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">Dataset</span>

<span class="kn">from</span> <span class="n">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>
<span class="kn">from</span> <span class="n">accelerate.utils</span> <span class="kn">import</span> <span class="n">set_seed</span><span class="p">,</span> <span class="n">DataLoaderConfiguration</span>
<span class="kn">import</span> <span class="n">os</span>

<span class="c1"># from torchdata.stateful_dataloader import StatefulDataLoader
</span>
<span class="c1"># Simple dataset with 10 elements
</span><span class="k">class</span> <span class="nc">SimpleDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

<span class="c1"># Function to print batch order in an epoch
</span><span class="k">def</span> <span class="nf">print_epoch_batches</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">interrupt</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>

    <span class="n">output</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="se">\n</span><span class="s">--- Process </span><span class="si">{</span><span class="n">accelerator</span><span class="p">.</span><span class="n">process_index</span><span class="si">}</span><span class="s"> ---</span><span class="se">\n</span><span class="sh">"</span>
    <span class="n">output</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">Epoch </span><span class="si">{</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s">:</span><span class="se">\n</span><span class="sh">"</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
        <span class="n">data</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">batch</span><span class="p">.</span><span class="nf">tolist</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">interrupt</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">accelerator</span><span class="p">.</span><span class="nf">save_state</span><span class="p">(</span><span class="n">output_dir</span><span class="o">=</span><span class="sh">"</span><span class="s">debug_data_order_checkpoints</span><span class="sh">"</span><span class="p">)</span>
            <span class="n">output</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">Random state saved</span><span class="se">\n</span><span class="sh">"</span>
    <span class="n">output</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">data</span><span class="si">}</span><span class="se">\n</span><span class="sh">"</span>
    <span class="k">return</span> <span class="n">output</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="sh">"</span><span class="s">__main__</span><span class="sh">"</span><span class="p">:</span>
    <span class="n">dataloader_config</span> <span class="o">=</span> <span class="nc">DataLoaderConfiguration</span><span class="p">(</span>
        <span class="n">use_stateful_dataloader</span><span class="o">=</span><span class="bp">True</span>
    <span class="p">)</span>
    <span class="n">accelerator</span> <span class="o">=</span> <span class="nc">Accelerator</span><span class="p">(</span>
        <span class="n">dataloader_config</span><span class="o">=</span><span class="n">dataloader_config</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="nf">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

    <span class="c1"># Create the dataset and DataLoader with shuffle=True
</span>    <span class="n">dataset</span> <span class="o">=</span> <span class="nc">SimpleDataset</span><span class="p">()</span>
    <span class="n">dataloader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span>
        <span class="n">dataset</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">dataloader</span> <span class="o">=</span> <span class="n">accelerator</span><span class="p">.</span><span class="nf">prepare</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>

    <span class="c1"># Check data order for 3 epochs
</span>    <span class="n">all_outputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
        <span class="n">epoch_output</span> <span class="o">=</span> <span class="nf">print_epoch_batches</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">interrupt</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">all_outputs</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">epoch_output</span><span class="p">)</span>

    <span class="c1"># Print all outputs at the end
</span>    <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">all_outputs</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

    <span class="n">accelerator</span><span class="p">.</span><span class="nf">wait_for_everyone</span><span class="p">()</span>

    <span class="c1"># Resume from checkpoint
</span>    <span class="n">accelerator</span> <span class="o">=</span> <span class="nc">Accelerator</span><span class="p">(</span>
        <span class="n">dataloader_config</span><span class="o">=</span><span class="n">dataloader_config</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="nf">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">dataloader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span>
        <span class="n">dataset</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">dataloader</span> <span class="o">=</span> <span class="n">accelerator</span><span class="p">.</span><span class="nf">prepare</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>

    <span class="c1"># Load random state
</span>    <span class="k">if</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">exists</span><span class="p">(</span><span class="sh">"</span><span class="s">debug_data_order_checkpoints</span><span class="sh">"</span><span class="p">):</span>
        <span class="n">accelerator</span><span class="p">.</span><span class="nf">load_state</span><span class="p">(</span><span class="sh">"</span><span class="s">debug_data_order_checkpoints</span><span class="sh">"</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Random state loaded from debug_data_order_checkpoints</span><span class="sh">"</span><span class="p">)</span>

    <span class="c1"># skip_dataloader = accelerator.skip_first_batches(dataloader, 2)
</span>
    <span class="c1"># Check data order for 1 epoch
</span>    <span class="n">all_outputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">):</span>
        <span class="n">epoch_output</span> <span class="o">=</span> <span class="nf">print_epoch_batches</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">)</span>
        <span class="n">all_outputs</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">epoch_output</span><span class="p">)</span>

    <span class="c1"># Print all outputs at the end
</span>    <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">all_outputs</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</code></pre></div></div>

<p>运行<code class="language-plaintext highlighter-rouge">accelerate launch --multi_gpu --num_processes 2 a.py</code>，输出</p>

<pre><code class="language-txt">--- Process 0 ---
Epoch 1:
[[4], [8], [1], [0], [5]]


--- Process 0 ---
Epoch 2:
Random state saved
[[6], [3], [5], [7], [1]]


--- Process 0 ---
Epoch 3:
[[3], [9], [1], [7], [2]]


--- Process 1 ---
Epoch 1:
[[2], [9], [7], [3], [6]]


--- Process 1 ---
Epoch 2:
Random state saved
[[2], [8], [4], [9], [0]]


--- Process 1 ---
Epoch 3:
[[4], [0], [8], [6], [5]]

Random state loaded from debug_data_order_checkpoints
Random state loaded from debug_data_order_checkpoints

--- Process 0 ---
Epoch 2:
[[8], [1], [0], [5]]


--- Process 0 ---
Epoch 3:
[[6], [3], [5], [7], [1]]


--- Process 1 ---
Epoch 2:
[[9], [7], [3], [6]]


--- Process 1 ---
Epoch 3:
[[2], [8], [4], [9], [0]]
</code></pre>

<p>可以看出StatefulDataloader即使不出现兼容性问题，也无法正确恢复epoch信息，因为此时的dataloader是依赖于全局随机环境的。</p>

<h2 id="test-4">Test 4</h2>

<p>对于程序：</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">from</span> <span class="n">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">Dataset</span>

<span class="kn">from</span> <span class="n">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>
<span class="kn">from</span> <span class="n">accelerate.utils</span> <span class="kn">import</span> <span class="n">set_seed</span><span class="p">,</span> <span class="n">DataLoaderConfiguration</span>
<span class="kn">import</span> <span class="n">os</span>

<span class="c1"># from torchdata.stateful_dataloader import StatefulDataLoader
</span>
<span class="c1"># Simple dataset with 10 elements
</span><span class="k">class</span> <span class="nc">SimpleDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

<span class="c1"># Function to print batch order in an epoch
</span><span class="k">def</span> <span class="nf">print_epoch_batches</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">interrupt</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>

    <span class="n">output</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="se">\n</span><span class="s">--- Process </span><span class="si">{</span><span class="n">accelerator</span><span class="p">.</span><span class="n">process_index</span><span class="si">}</span><span class="s"> ---</span><span class="se">\n</span><span class="sh">"</span>
    <span class="n">output</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">Epoch </span><span class="si">{</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s">:</span><span class="se">\n</span><span class="sh">"</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
        <span class="n">data</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">batch</span><span class="p">.</span><span class="nf">tolist</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">interrupt</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">accelerator</span><span class="p">.</span><span class="nf">save_state</span><span class="p">(</span><span class="n">output_dir</span><span class="o">=</span><span class="sh">"</span><span class="s">debug_data_order_checkpoints</span><span class="sh">"</span><span class="p">)</span>
            <span class="n">output</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">Random state saved</span><span class="se">\n</span><span class="sh">"</span>
    <span class="n">output</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">data</span><span class="si">}</span><span class="se">\n</span><span class="sh">"</span>
    <span class="k">return</span> <span class="n">output</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="sh">"</span><span class="s">__main__</span><span class="sh">"</span><span class="p">:</span>
    <span class="n">dataloader_config</span> <span class="o">=</span> <span class="nc">DataLoaderConfiguration</span><span class="p">(</span>
        <span class="n">use_seedable_sampler</span><span class="o">=</span><span class="bp">True</span>
    <span class="p">)</span>
    <span class="n">accelerator</span> <span class="o">=</span> <span class="nc">Accelerator</span><span class="p">(</span>
        <span class="n">dataloader_config</span><span class="o">=</span><span class="n">dataloader_config</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="nf">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

    <span class="c1"># Create the dataset and DataLoader with shuffle=True
</span>    <span class="n">dataset</span> <span class="o">=</span> <span class="nc">SimpleDataset</span><span class="p">()</span>
    <span class="n">dataloader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span>
        <span class="n">dataset</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">dataloader</span> <span class="o">=</span> <span class="n">accelerator</span><span class="p">.</span><span class="nf">prepare</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>

    <span class="c1"># Check data order for 3 epochs
</span>    <span class="n">all_outputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
        <span class="n">epoch_output</span> <span class="o">=</span> <span class="nf">print_epoch_batches</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">interrupt</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">all_outputs</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">epoch_output</span><span class="p">)</span>

    <span class="c1"># Print all outputs at the end
</span>    <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">all_outputs</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

    <span class="n">accelerator</span><span class="p">.</span><span class="nf">wait_for_everyone</span><span class="p">()</span>

    <span class="c1"># Resume from checkpoint
</span>    <span class="n">accelerator</span> <span class="o">=</span> <span class="nc">Accelerator</span><span class="p">(</span>
        <span class="n">dataloader_config</span><span class="o">=</span><span class="n">dataloader_config</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="nf">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">dataloader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span>
        <span class="n">dataset</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">dataloader</span> <span class="o">=</span> <span class="n">accelerator</span><span class="p">.</span><span class="nf">prepare</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>

    <span class="c1"># Load random state
</span>    <span class="k">if</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">exists</span><span class="p">(</span><span class="sh">"</span><span class="s">debug_data_order_checkpoints</span><span class="sh">"</span><span class="p">):</span>
        <span class="n">accelerator</span><span class="p">.</span><span class="nf">load_state</span><span class="p">(</span><span class="sh">"</span><span class="s">debug_data_order_checkpoints</span><span class="sh">"</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Random state loaded from debug_data_order_checkpoints</span><span class="sh">"</span><span class="p">)</span>

    <span class="c1"># skip_dataloader = accelerator.skip_first_batches(dataloader, 2)
</span>
    <span class="c1"># Check data order for 1 epoch
</span>    <span class="n">dataloader</span><span class="p">.</span><span class="nf">set_epoch</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">all_outputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">):</span>
        <span class="n">epoch_output</span> <span class="o">=</span> <span class="nf">print_epoch_batches</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">)</span>
        <span class="n">all_outputs</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">epoch_output</span><span class="p">)</span>

    <span class="c1"># Print all outputs at the end
</span>    <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">all_outputs</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</code></pre></div></div>

<p>运行<code class="language-plaintext highlighter-rouge">accelerate launch --multi_gpu --num_processes 2 a.py</code>，输出</p>

<pre><code class="language-txt">--- Process 0 ---
Epoch 1:
[[2], [1], [4], [0], [3]]


--- Process 0 ---
Epoch 2:
Random state saved
[[8], [9], [5], [6], [2]]


--- Process 0 ---
Epoch 3:
[[2], [3], [7], [1], [5]]


--- Process 1 ---
Epoch 1:
[[6], [8], [5], [9], [7]]


--- Process 1 ---
Epoch 2:
Random state saved
[[4], [0], [1], [7], [3]]


--- Process 1 ---
Epoch 3:
[[6], [8], [9], [4], [0]]

Random state loaded from debug_data_order_checkpointsRandom state loaded from debug_data_order_checkpoints


--- Process 1 ---
Epoch 2:
[[4], [0], [1], [7], [3]]


--- Process 1 ---
Epoch 3:
[[6], [8], [9], [4], [0]]


--- Process 0 ---
Epoch 2:
[[8], [9], [5], [6], [2]]


--- Process 0 ---
Epoch 3:
[[2], [3], [7], [1], [5]]
</code></pre>

<p>可以看出<code class="language-plaintext highlighter-rouge">use_seedable_sampler</code>是正常的</p>

<h2 id="test-5">Test 5</h2>
<p>对于程序：</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">from</span> <span class="n">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">Dataset</span>

<span class="kn">from</span> <span class="n">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>
<span class="kn">from</span> <span class="n">accelerate.utils</span> <span class="kn">import</span> <span class="n">set_seed</span><span class="p">,</span> <span class="n">DataLoaderConfiguration</span>
<span class="kn">import</span> <span class="n">os</span>

<span class="c1"># from torchdata.stateful_dataloader import StatefulDataLoader
</span>
<span class="c1"># Simple dataset with 10 elements
</span><span class="k">class</span> <span class="nc">SimpleDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

<span class="c1"># Function to print batch order in an epoch
</span><span class="k">def</span> <span class="nf">print_epoch_batches</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">interrupt</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>

    <span class="n">output</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="se">\n</span><span class="s">--- Process </span><span class="si">{</span><span class="n">accelerator</span><span class="p">.</span><span class="n">process_index</span><span class="si">}</span><span class="s"> ---</span><span class="se">\n</span><span class="sh">"</span>
    <span class="n">output</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">Epoch </span><span class="si">{</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s">:</span><span class="se">\n</span><span class="sh">"</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
        <span class="n">data</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">batch</span><span class="p">.</span><span class="nf">tolist</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">interrupt</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">accelerator</span><span class="p">.</span><span class="nf">save_state</span><span class="p">(</span><span class="n">output_dir</span><span class="o">=</span><span class="sh">"</span><span class="s">debug_data_order_checkpoints</span><span class="sh">"</span><span class="p">)</span>
            <span class="n">output</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">Random state saved</span><span class="se">\n</span><span class="sh">"</span>
    <span class="n">output</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">data</span><span class="si">}</span><span class="se">\n</span><span class="sh">"</span>
    <span class="k">return</span> <span class="n">output</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="sh">"</span><span class="s">__main__</span><span class="sh">"</span><span class="p">:</span>
    <span class="n">dataloader_config</span> <span class="o">=</span> <span class="nc">DataLoaderConfiguration</span><span class="p">(</span>
        <span class="n">use_stateful_dataloader</span><span class="o">=</span><span class="bp">True</span>
    <span class="p">)</span>
    <span class="n">accelerator</span> <span class="o">=</span> <span class="nc">Accelerator</span><span class="p">(</span>
        <span class="n">dataloader_config</span><span class="o">=</span><span class="n">dataloader_config</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="nf">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

    <span class="c1"># Create the dataset and DataLoader with shuffle=True
</span>    <span class="n">dataset</span> <span class="o">=</span> <span class="nc">SimpleDataset</span><span class="p">()</span>
    <span class="n">dataloader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span>
        <span class="n">dataset</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">dataloader</span> <span class="o">=</span> <span class="n">accelerator</span><span class="p">.</span><span class="nf">prepare</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>

    <span class="c1"># Check data order for 3 epochs
</span>    <span class="n">all_outputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
        <span class="n">epoch_output</span> <span class="o">=</span> <span class="nf">print_epoch_batches</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">interrupt</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">all_outputs</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">epoch_output</span><span class="p">)</span>

    <span class="c1"># Print all outputs at the end
</span>    <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">all_outputs</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

    <span class="n">accelerator</span><span class="p">.</span><span class="nf">wait_for_everyone</span><span class="p">()</span>

    <span class="c1"># Resume from checkpoint
</span>    <span class="n">accelerator</span> <span class="o">=</span> <span class="nc">Accelerator</span><span class="p">(</span>
        <span class="n">dataloader_config</span><span class="o">=</span><span class="n">dataloader_config</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="nf">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">dataloader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span>
        <span class="n">dataset</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">dataloader</span> <span class="o">=</span> <span class="n">accelerator</span><span class="p">.</span><span class="nf">prepare</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>

    <span class="c1"># Load random state
</span>    <span class="k">if</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">exists</span><span class="p">(</span><span class="sh">"</span><span class="s">debug_data_order_checkpoints</span><span class="sh">"</span><span class="p">):</span>
        <span class="n">accelerator</span><span class="p">.</span><span class="nf">load_state</span><span class="p">(</span><span class="sh">"</span><span class="s">debug_data_order_checkpoints</span><span class="sh">"</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Random state loaded from debug_data_order_checkpoints</span><span class="sh">"</span><span class="p">)</span>

    <span class="c1"># skip_dataloader = accelerator.skip_first_batches(dataloader, 2)
</span>
    <span class="c1"># Check data order for 1 epoch
</span>    <span class="n">all_outputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">):</span>
        <span class="n">current_dataloader</span> <span class="o">=</span> <span class="n">dataloader</span>
        <span class="k">if</span> <span class="n">epoch</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># skip first 2 batches in epoch 2
</span>            <span class="n">current_dataloader</span> <span class="o">=</span> <span class="n">accelerator</span><span class="p">.</span><span class="nf">skip_first_batches</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">epoch_output</span> <span class="o">=</span> <span class="nf">print_epoch_batches</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">current_dataloader</span><span class="p">)</span>
        <span class="n">all_outputs</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">epoch_output</span><span class="p">)</span>

    <span class="c1"># Print all outputs at the end
</span>    <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">all_outputs</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</code></pre></div></div>

<p>运行<code class="language-plaintext highlighter-rouge">accelerate launch --multi_gpu --num_processes 2 a.py</code>，输出</p>

<pre><code class="language-txt">--- Process 1 ---
Epoch 1:
[[2], [9], [7], [3], [6]]


--- Process 1 ---
Epoch 2:
Random state saved
[[2], [8], [4], [9], [0]]


--- Process 1 ---
Epoch 3:
[[4], [0], [8], [6], [5]]


--- Process 0 ---
Epoch 1:
[[4], [8], [1], [0], [5]]


--- Process 0 ---
Epoch 2:
Random state saved
[[6], [3], [5], [7], [1]]


--- Process 0 ---
Epoch 3:
[[3], [9], [1], [7], [2]]

Random state loaded from debug_data_order_checkpoints
Random state loaded from debug_data_order_checkpoints

--- Process 1 ---
Epoch 2:
[[7], [3], [6]]


--- Process 1 ---
Epoch 3:
[[8], [4], [9], [0]]


--- Process 0 ---
Epoch 2:
[[1], [0], [5]]


--- Process 0 ---
Epoch 3:
[[3], [5], [7], [1]]
</code></pre>

<p>可以发现Stateful Dataloader与skip_first_batches这类方法<strong>不兼容</strong>，会导致第二个epoch也有内容被跳过</p>

    </div>
  </article>

  

  

  
    
      



    
  

  
  
    <div id="giscus_thread" style="max-width: 1200px; margin: 0 auto;">
  
    <br>
  

  
    <script defer src="/assets/js/giscus-setup.js"></script>
    <noscript>
      Please enable JavaScript to view the
      <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a>
    </noscript>
  
</div>

  
</div>

      
    </div>

    <!-- Footer -->
    


  <footer class="fixed-bottom" role="contentinfo">
    <div class="container mt-0">
      
  © Copyright 2025
  Yumin
  
  Zhuang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.cloudflare.com/" target="_blank" rel="external nofollow noopener">Cloudflare Pages</a>.

  
  
    Last updated: December 11, 2025.
  

    </div>
  </footer>



    <!-- JavaScripts -->
    <!-- jQuery -->
<script src="/assets/libs/jquery/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

<!-- Bootsrap & MDB scripts -->
<script src="/assets/js/bootstrap.bundle.min.js"></script>
<script src="/assets/libs/mdb/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>


  <!-- Masonry & imagesLoaded -->
  <script defer src="/assets/libs/masonry/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="/assets/libs/imagesloaded/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script>























  <!-- Medium Zoom JS -->
  <script defer src="/assets/libs/medium_zoom/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script>






<!-- Load Common JS -->
<script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script>
<script defer src="/assets/js/common.js?c15de51d4bb57887caa2c21988d97279"></script>
<script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script>

<!-- Jupyter Open External Links New Tab -->
<script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script>

<!-- Badges -->

  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>


  <script async src="https://badge.dimensions.ai/badge.js"></script>



  <!-- MathJax -->
  <script defer type="text/javascript" id="MathJax-script" src="/assets/libs/mathjax/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script>
  
    <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script>
    <script defer src="/assets/libs/polyfill/polyfill.min.js" crossorigin="anonymous"></script>
  









  <!-- Scrolling Progress Bar -->
  <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script>







  <!-- Back to Top -->
  <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script>
  <script>
    addBackToTop();
  </script>



  <!-- Search -->
  <script type="module" src="/assets/js/search/ninja-keys.min.js?230637657ac0b42e92d76e2b4c1b4764"></script>
  <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys>
  <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script>
  <script src="/assets/js/search-data.js"></script>
  <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script>




  </body>
</html>
